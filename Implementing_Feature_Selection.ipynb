{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%reset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKYQP60jRGBd",
        "outputId": "d10ab246-6454-4276-fe0d-939e44e00934"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fpcshA11mdCC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {\n",
        "    'us_crime': \"https://archive.ics.uci.edu/static/public/183/data.csv\",\n",
        "    'letter_img': \"https://archive.ics.uci.edu/static/public/59/data.csv\",\n",
        "    'mammography': \"https://archive.ics.uci.edu/static/public/161/data.csv\"\n",
        "}\n",
        "\n",
        "data_dict = {}\n",
        "for name, url in datasets.items():\n",
        "    data = pd.read_csv(url, header=None)\n",
        "\n",
        "    if name == 'us_crime':\n",
        "        data = data.drop(columns=[3])\n",
        "        X = data.iloc[1:, :-1]\n",
        "        y = data.iloc[1:, -1].astype(float).apply(lambda x: 1 if x > 0.65 else 0).astype(int)  # Target is the last column\n",
        "    elif name == 'letter_img':\n",
        "        X = data.iloc[1:, 1:]  # Features start from the second column\n",
        "        y = data.iloc[1:, 0].apply(lambda x: 1 if x == 'Z' else 0).astype(int)   # Target is the first column\n",
        "    elif name == 'mammography':\n",
        "        X = data.iloc[1:, :-1]\n",
        "        y = data.iloc[1:, -1].astype(int)  # Target is the last column\n",
        "    data_dict[name] = (X, y)\n"
      ],
      "metadata": {
        "id": "wG99zXSjpVE9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_scores_multiple_splits(X, y, num_splits= 10):\n",
        "    # multiple splits (tests) for having a more reliable and accurate features.\n",
        "    f1_scores = []\n",
        "    for _ in range(num_splits):\n",
        "      random_state = np.random.randint(100) # Generate a random seed\n",
        "      for i in range(X.shape[1]):\n",
        "          X_feature = X.iloc[:, i].values.reshape(-1, 1)\n",
        "\n",
        "          # Convert '?' to NaN and then impute missing values\n",
        "          X_feature = np.where(X_feature == '?', np.nan, X_feature)\n",
        "          imputer = SimpleImputer(strategy='median') # Or another suitable strategy\n",
        "          X_feature = imputer.fit_transform(X_feature)\n",
        "\n",
        "          X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.25, random_state= random_state) #random_state for having the mix of examples.\n",
        "\n",
        "\n",
        "          clf = DecisionTreeClassifier()\n",
        "          clf.fit(X_train, y_train)\n",
        "          y_pred = clf.predict(X_test)\n",
        "\n",
        "          average = 'binary'\n",
        "          f1 = f1_score(y_test, y_pred, average= average)\n",
        "          f1_scores.append(f1)\n",
        "\n",
        "    return np.array(f1_scores).reshape(num_splits, -1) # Reshape for easy averaging\n"
      ],
      "metadata": {
        "id": "IVZxz3T7rcVb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_svm_with_selected_features_multiple_splits(X, y, feature_ranking, fractions, num_splits= 10):\n",
        "    results_all= []\n",
        "    for _ in range(num_splits):\n",
        "      random_state= np.random.randint(100)\n",
        "      results = {'fraction': [], 'f1_score': [], 'precision': [], 'recall': []}\n",
        "      for fraction in fractions:\n",
        "          num_features = max(1, int(fraction * X.shape[1])) # ensure that at least one feature is selected.\n",
        "          selected_features = feature_ranking[:num_features]\n",
        "          X_selected = X.iloc[:, selected_features]\n",
        "\n",
        "          # Convert '?' to NaN and then impute missing values\n",
        "          X_selected = np.where(X_selected == '?', np.nan, X_selected)\n",
        "          imputer = SimpleImputer(strategy='median') #most_frequent\n",
        "          X_selected = imputer.fit_transform(X_selected)\n",
        "\n",
        "          X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25, random_state= random_state)\n",
        "\n",
        "          scaler = StandardScaler()\n",
        "          X_train = scaler.fit_transform(X_train)\n",
        "          X_test = scaler.transform(X_test)\n",
        "\n",
        "          svm = SVC(kernel='rbf', class_weight= 'balanced')\n",
        "          svm.fit(X_train, y_train)\n",
        "          y_pred = svm.predict(X_test)\n",
        "\n",
        "          average = 'binary'\n",
        "          f1 = f1_score(y_test, y_pred, average= average)\n",
        "          precision = precision_score(y_test, y_pred, average= average)\n",
        "          recall = recall_score(y_test, y_pred, average= average)\n",
        "\n",
        "          results['fraction'].append(fraction)\n",
        "          results['f1_score'].append(f1)\n",
        "          results['precision'].append(precision)\n",
        "          results['recall'].append(recall)\n",
        "      results_all.append(results)\n",
        "    return results_all\n"
      ],
      "metadata": {
        "id": "sVrPDlk2rkEP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ranking\n",
        "# f1_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6VAhLtXDSka",
        "outputId": "9b91c2cc-9fd3-42bc-b28f-369cb36eb7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.798076923076923,\n",
              " 0.798076923076923,\n",
              " 0.798076923076923,\n",
              " 0.7981220657276995,\n",
              " 0.7981220657276995,\n",
              " 0.8389830508474576,\n",
              " 0.8389830508474576,\n",
              " 0.8189655172413793,\n",
              " 0.8189655172413793,\n",
              " 0.8189655172413793]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "\n",
        "for name, (X, y) in data_dict.items():\n",
        "    print(f\"Evaluating dataset: {name}\")\n",
        "    print(f\"  X shape: {X.shape}\")\n",
        "    print(f\"  y shape: {y.shape}\")\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    ratio = int(counts[np.argmax(counts)] / counts[np.argmin(counts)])\n",
        "    print(f\"  Ratio: {ratio}:1\")\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    f1_scores_multiple = calculate_f1_scores_multiple_splits(X, y)\n",
        "    f1_scores= f1_scores_multiple.mean(axis=0) # Average across rows (splits)\n",
        "\n",
        "    # Rank features based on F1-scores\n",
        "    feature_ranking = np.argsort(f1_scores)[::-1]\n",
        "\n",
        "    # Evaluate SVM classifier with selected features\n",
        "    results_multiple = evaluate_svm_with_selected_features_multiple_splits(X, y, feature_ranking, fractions)\n",
        "\n",
        "    # Calculate average scores for each fraction\n",
        "    average_f1_scores = []\n",
        "    average_precision_scores = []\n",
        "    average_recall_scores = []\n",
        "\n",
        "    for fraction in fractions:\n",
        "        f1_scores_for_fraction = [result['f1_score'][fractions.index(fraction)] for result in results_multiple]\n",
        "        precision_scores_for_fraction = [result['precision'][fractions.index(fraction)] for result in results_multiple]\n",
        "        recall_scores_for_fraction = [result['recall'][fractions.index(fraction)] for result in results_multiple]\n",
        "\n",
        "        average_f1_scores.append(np.mean(f1_scores_for_fraction))\n",
        "        average_precision_scores.append(np.mean(precision_scores_for_fraction))\n",
        "        average_recall_scores.append(np.mean(recall_scores_for_fraction))\n",
        "\n",
        "    # Now we have average scores for each fraction across multiple splits\n",
        "    # Use these average scores for plotting instead of the single-split scores\n",
        "    f1_scores = average_f1_scores\n",
        "    recall_scores = average_recall_scores\n",
        "    precision_scores = average_precision_scores\n",
        "    # # Extract the scores for plotting\n",
        "    # f1_scores = results['f1_score']\n",
        "    # recall_scores = results['recall']\n",
        "    # precision_scores = results['precision']\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot F1-score\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(fractions[: -1], f1_scores[: -1], color= \"blue\")\n",
        "    plt.axhline(y= f1_scores[-1], xmin= 0, xmax= 1.0+ 0.05,\n",
        "            label='Full set', color=\"red\", linestyle='--')\n",
        "\n",
        "    plt.title(f'F1-score ({name})')\n",
        "    plt.xlabel('Fraction of Features')\n",
        "    plt.ylabel('F1-score')\n",
        "    plt.grid(True, color='white')\n",
        "    plt.gca().set_facecolor('lightblue')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Recall score\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(fractions[: -1], recall_scores[: -1], color= \"blue\")\n",
        "    plt.axhline(y= recall_scores[-1], xmin= 0, xmax= 1.0+ 0.05,\n",
        "            label='Full set', color=\"red\", linestyle='--')\n",
        "\n",
        "    plt.title(f'Recall ({name})')\n",
        "    plt.xlabel('Fraction of Features')\n",
        "    plt.ylabel('Recall Score')\n",
        "    plt.grid(True, color='white')\n",
        "    plt.gca().set_facecolor('lightblue')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Precision score\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(fractions[: -1], precision_scores[: -1], color= \"blue\")\n",
        "    plt.axhline(y= precision_scores[-1], xmin= 0, xmax= 1.0+ 0.05,\n",
        "            label='Full set', color=\"red\", linestyle='--')\n",
        "\n",
        "    plt.title(f'Precision ({name})')\n",
        "    plt.xlabel('Fraction of Features')\n",
        "    plt.ylabel('Precision Score')\n",
        "    plt.grid(True, color='white')  # White grid lines\n",
        "    plt.gca().set_facecolor('lightblue')  # Light blue background\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"The best fraction of features in this problem based on the F1-score is\", fractions[f1_scores.index(max(f1_scores))])\n",
        "    print(\"Therefore we can use the above fraction as an optima.\")\n",
        "    print(20* '*', '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16MzZkNNr1kw",
        "outputId": "97218337-d00e-49d6-8b3b-8d1304c66d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating dataset: us_crime\n",
            "  X shape: (1994, 126)\n",
            "  y shape: (1994,)\n",
            "  Ratio: 12:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This shows that we do not necessarily need to use all the features for having a good ML model.**"
      ],
      "metadata": {
        "id": "9sOlLQDbVcwD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8dAC8Xjox0xq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}